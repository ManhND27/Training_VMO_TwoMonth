{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "interpreter": {
   "hash": "c2a992d86943bdbb1a93721aa8faf11a2d48a4b1fd05bac4b69f4b63e0ef12fd"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\r\n",
    "\r\n",
    "def sgd(\r\n",
    "    gradient, x, y, start, learn_rate=0.1, batch_size=1, epoch=50, tolerance=1e-06, dtype=\"float64\", random_state=None\r\n",
    "):  \r\n",
    "    #checking gradient\r\n",
    "    if not callable(gradient):\r\n",
    "        raise TypeError(\"'gradient' must be callable\")\r\n",
    "\r\n",
    "    #create dtype\r\n",
    "    dtype_ = np.dtype(dtype)\r\n",
    "\r\n",
    "    #checking x, y\r\n",
    "    x, y = np.array(x, dtype=dtype_), np.array(y, dtype=dtype_)\r\n",
    "    if x.shape[0] != y.shape[0]:\r\n",
    "        raise ValueError(\"'x' and 'y' lengths do not match\")\r\n",
    "\r\n",
    "    #checking start\r\n",
    "    vector = np.array(start, dtype=dtype_)\r\n",
    "    \r\n",
    "    #Checking and create seed\r\n",
    "    seed = None if random_state is None else int(random_state)\r\n",
    "    np.random.seed(seed=seed)\r\n",
    "\r\n",
    "    #checking learn rate\r\n",
    "    learn_rate = np.array(learn_rate, dtype=dtype_)\r\n",
    "    if np.any(learn_rate <= 0):\r\n",
    "        raise ValueError(\"'learn_rate' must be greater than zero\")\r\n",
    "\r\n",
    "    # checking batch size\r\n",
    "    batch_size = int(batch_size)\r\n",
    "    if not 0 < batch_size <= x.shape[0]:\r\n",
    "        raise ValueError(\r\n",
    "            \"'batch_size' must be greater than zero and less than \"\r\n",
    "            \"or equal to the number of observations\"\r\n",
    "        )\r\n",
    "\r\n",
    "    #checking epoch\r\n",
    "    epoch = int(epoch)\r\n",
    "    if epoch <= 0:\r\n",
    "        raise ValueError(\"'n_iter' must be greater than zero\")\r\n",
    "\r\n",
    "    # Checking tolerance\r\n",
    "    tolerance = np.array(tolerance, dtype=dtype_)\r\n",
    "    if np.any(tolerance <= 0):\r\n",
    "        raise ValueError(\"'tolerance' must be greater than zero\")\r\n",
    "\r\n",
    "\r\n",
    "    z = np.c_[x.reshape(len(x), -1), y.reshape(len(y), 1)]\r\n",
    "    iterations = int(x.shape[0] / int(batch_size))\r\n",
    "    for _ in range(epoch):\r\n",
    "        np.random.shuffle(z)\r\n",
    "        x_2, y_2 = z[0:len(x), :-1], z[0:len(y), -1:]\r\n",
    "        \r\n",
    "        start = 0\r\n",
    "        stop = batch_size\r\n",
    "        for _ in range(iterations):\r\n",
    "            x_batch = x[start: stop]\r\n",
    "            y_batch = y[start: stop]\r\n",
    "            diff = -learn_rate * np.array(gradient(x_batch, y_batch, vector))\r\n",
    "            start += batch_size\r\n",
    "            stop += batch_size\r\n",
    "\r\n",
    "        if np.all(np.abs(diff) <= tolerance):\r\n",
    "            break\r\n",
    "        vector += diff\r\n",
    "    return vector\r\n",
    "\r\n",
    "def ssr_gradient(x, y, b):\r\n",
    "    res = b[0] + b[1] * x - y\r\n",
    "    return res.mean(), (res * x).mean()\r\n",
    "\r\n",
    "x = np.array([5, 15, 25, 35, 45, 55])\r\n",
    "y = np.array([5, 20, 14, 32, 22, 38])\r\n",
    "\r\n",
    "print(sgd(ssr_gradient, x, y, start=[0.5, 0.5], learn_rate=0.0008, epoch=100_000, batch_size=3))"
   ]
  }
 ]
}